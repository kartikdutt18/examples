{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Time Series Prediction Using LSTM\n",
    "In this example, we will implement an LSTM using mlpack to forecast multivariate time series data. This notebook contains step by step walkthrough for time series prediction using LSTMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Setup\n",
    "Include all libraries required to implement this tutorial. These mainly include files from mlpack, ensmallen and armadillo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <mlpack/core.hpp>\n",
    "#include <mlpack/prereqs.hpp>\n",
    "#include <mlpack/methods/ann/rnn.hpp>\n",
    "#include <mlpack/methods/ann/layer/layer.hpp>\n",
    "#include <mlpack/core/data/scaler_methods/min_max_scaler.hpp>\n",
    "#include <mlpack/methods/ann/init_rules/he_init.hpp>\n",
    "#include <mlpack/methods/ann/loss_functions/mean_squared_error.hpp>\n",
    "#include <mlpack/core/data/split_data.hpp>\n",
    "#include <ensmallen.hpp>\n",
    "#include <armadillo>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some convienent namespaces to simplify the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using namespace mlpack;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using namespace mlpack::ann;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using namespace arma;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "using namespace std;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Set Model and Training parameters.\n",
    "Set the training parameters for the model.\n",
    "Parameters include step-size for optimizer, ratio for train-test split, batch-size for training, look-back-parameter for LSTM and number of hidden cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "// If true, the model will be trained; if false, the saved model will be\n",
    "// read and used for prediction\n",
    "// NOTE: Training the model may take a long time, therefore once it is\n",
    "// trained you can set this to false and use the model for prediction.\n",
    "// NOTE: There is no error checking in this example to see if the trained\n",
    "// model exists!\n",
    "const bool bTrain = true;\n",
    "// You can load and further train a model by setting this to true.\n",
    "const bool bLoadAndTrain = false;\n",
    "\n",
    "// Testing data is taken from the dataset in this ratio.\n",
    "const double RATIO = 0.1;\n",
    "\n",
    "// Step size of an optimizer.\n",
    "const double STEP_SIZE = 5e-5;\n",
    "\n",
    "// Number of cells in the LSTM (hidden layers in standard terms).\n",
    "// NOTE: you may play with this variable in order to further optimize the\n",
    "// model (as more cells are added, accuracy is likely to go up, but training\n",
    "// time may take longer).\n",
    "const int H1 = 16;\n",
    "\n",
    "// Number of data points in each iteration of SGD.\n",
    "const size_t BATCH_SIZE = 16;\n",
    "\n",
    "// Nunmber of timesteps to look backward for in the RNN.\n",
    "const int rho = 16;\n",
    "\n",
    "// Max Rho for LSTM.\n",
    "const int maxRho = rho;\n",
    "\n",
    "// Number of epochs for training.\n",
    "const int EPOCHS = 250;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set paths for the dataset, trained model and final predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Change the names of these files as necessary. They should be correct\n",
    "// already, if your program's working directory contains the data and/or\n",
    "// model.\n",
    "const std::string dataFile = \"Google2016-2019.csv\";\n",
    "// Path where the model will be saved.\n",
    "const std::string modelFile = \"lstm_multi.bin\";\n",
    "// Path where the final predicitions will be stored.\n",
    "const std::string predFile = \"lstm_multi_predictions.csv\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading and Preprocess the Dataset.\n",
    "Dataset will be loaded and preprocessed for the model. If we want to predict the Google stock price correctly then we need to consider the volume of the stocks traded, the closing, opening, high and low values of the stock price from the previous days. This is a time series problem. We will create data for the training of the RNN model that will go back 25 business days in the past for each time step. We will convert the input data to the time series format the RNN requires. We will take 30 % of the latest data as our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data ...\n"
     ]
    }
   ],
   "source": [
    "arma::mat dataset;\n",
    "\n",
    "// In Armadillo rows represent features, columns represent data points.\n",
    "std::cout << \"Reading data ...\" << std::endl;\n",
    "mlpack::data::Load(dataFile, dataset, true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0   6.6826e+02   6.8004e+02   6.8411e+02\n",
      "            0   2.6320e+06   2.1697e+06   1.9314e+06\n",
      "            0   6.7100e+02   6.7897e+02   6.8300e+02\n",
      "            0   6.7230e+02   6.8033e+02   6.8743e+02\n",
      "            0   6.6328e+02   6.7300e+02   6.8141e+02\n"
     ]
    }
   ],
   "source": [
    "// Visualize the first the rows of the dataset.\n",
    "dataset.submat(1, 0, dataset.n_rows - 1, 3).print()\n",
    "// Here each row represents: close, volume, open, high, low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the dataset.\n",
    "Since columns such as date and time are not needed we will drop them. We will also scale the data to increase stability in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "// The CSV file has a header, so it is necessary to remove it. In Armadillo's\n",
    "// representation it is the first column.\n",
    "// The first column in the CSV is the date which is not required, therefore\n",
    "// we remove it also (first row in in arma::mat).\n",
    "\n",
    "dataset = dataset.submat(1, 1, dataset.n_rows - 1, dataset.n_cols - 1);\n",
    "\n",
    "// We have 5 input data columns and 2 output columns (target).\n",
    "size_t inputSize = 5, outputSize = 2;\n",
    "\n",
    "// Split the dataset into training and validation sets.\n",
    "arma::mat trainData = dataset.submat(arma::span(),arma::span(0, (1 - RATIO) *\n",
    "      dataset.n_cols));\n",
    "arma::mat testData = dataset.submat(arma::span(), arma::span((1 - RATIO) * dataset.n_cols,\n",
    "      dataset.n_cols - 1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpack::data::MinMaxScaler scale;\n",
    "// Fit scaler only on training data.\n",
    "scale.Fit(trainData);\n",
    "scale.Transform(trainData, trainData);\n",
    "scale.Transform(testData, testData);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Time Series Dataset.\n",
    "The time series data for training the model contains the Closing stock price, the Volume of stocks traded, Opening stock price, Highest stock price and Lowest stock price for 'rho' days in the past. The two target variables (multivariate) we want to predict are the Highest stock price and Lowest stock price (high, low) for the next day!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "template<typename InputDataType = arma::mat,\n",
    "         typename DataType = arma::cube,\n",
    "         typename LabelType = arma::cube>\n",
    "void CreateTimeSeriesData(InputDataType dataset,\n",
    "                          DataType& X,\n",
    "                          LabelType& y,\n",
    "                          const size_t rho)\n",
    "{\n",
    "  for (size_t i = 0; i < dataset.n_cols - rho; i++)\n",
    "  {\n",
    "    X.subcube(arma::span(), arma::span(i), arma::span()) =\n",
    "        dataset.submat(arma::span(), arma::span(i, i + rho - 1));\n",
    "    y.subcube(arma::span(), arma::span(i), arma::span()) =\n",
    "        dataset.submat(arma::span(3, 4), arma::span(i + 1, i + rho));\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "// We need to individually create training and testing time series data.\n",
    "arma::cube trainX, trainY, testX, testY;\n",
    "trainX.set_size(inputSize, trainData.n_cols - rho + 1, rho);\n",
    "trainY.set_size(outputSize, trainData.n_cols - rho + 1, rho);\n",
    "testX.set_size(inputSize, testData.n_cols - rho + 1, rho);\n",
    "testY.set_size(outputSize, testData.n_cols - rho + 1, rho);\n",
    "\n",
    "// Create training sets for one-step-ahead regression.\n",
    "CreateTimeSeriesData(trainData, trainX, trainY, rho);\n",
    "// Create test sets for one-step-ahead regression.\n",
    "CreateTimeSeriesData(testData, testX, testY, rho);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Create the Model\n",
    "We add 3 LSTM modules that will be stacked one after the other in the RNN, implementing an efficient stacked RNN. Finally, the output will have 2 units the (high, low) values of the stock price for the next day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpack::ann::RNN<mlpack::ann::MeanSquaredError<>, mlpack::ann::HeInitialization> model(rho);\n",
    "\n",
    "if (bLoadAndTrain)\n",
    "{\n",
    "  // The model will be trained further.\n",
    "  std::cout << \"Loading and further training model...\" << std::endl;\n",
    "  data::Load(modelFile, \"LSTMMulti\", model);\n",
    "}\n",
    "else\n",
    "{\n",
    "  model.Add<mlpack::ann::IdentityLayer<> >();\n",
    "  model.Add<mlpack::ann::LSTM<> >(inputSize, H1, maxRho);\n",
    "  model.Add<mlpack::ann::Dropout<> >(0.2);\n",
    "  model.Add<mlpack::ann::LeakyReLU<> >();\n",
    "  model.Add<mlpack::ann::LSTM<> >(H1, H1, maxRho);\n",
    "  model.Add<mlpack::ann::Dropout<> >(0.2);\n",
    "  model.Add<mlpack::ann::LeakyReLU<> >();\n",
    "  model.Add<mlpack::ann::LSTM<> >(H1, H1, maxRho);\n",
    "  model.Add<mlpack::ann::ReLULayer<> >();\n",
    "  model.Add<mlpack::ann::Linear<> >(H1, outputSize);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.Training the model.\n",
    "We will use ensmallen to get the optimizer and train the model. For more details refer to the [documentation](https://www.ensmallen.org/docs.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Setting parameters Stochastic Gradient Descent (SGD) optimizer.\n",
    "ens::SGD<ens::AdamUpdate> optimizer(\n",
    "    STEP_SIZE, // Step size of the optimizer.\n",
    "    BATCH_SIZE, // Batch size. Number of data points that are used in each iteration.\n",
    "    trainData.n_cols * EPOCHS, // Max number of iterations.\n",
    "    1e-8,// Tolerance.\n",
    "    true, // Shuffle.\n",
    "    ens::AdamUpdate(1e-8, 0.9, 0.999)); // Adam update policy.\n",
    "\n",
    "optimizer.Tolerance() = -1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model.\n",
    "Here we will use ensmallen callbacks to train the model. We will be using stochastic gradient descent as an optimizer. To stop the training when the loss stops decreasing or doesn't show any improvement.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Epoch 1/4054\n",
      "0.526317\n",
      "42/42 [==================================================] 100% - 0s 9ms/step - loss: 0.526317\n",
      "Epoch 2/4054\n",
      "0.518579\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.518579\n",
      "Epoch 3/4054\n",
      "0.518346\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.518346\n",
      "Epoch 4/4054\n",
      "0.512323\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.512323\n",
      "Epoch 5/4054\n",
      "0.506368\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.506368\n",
      "Epoch 6/4054\n",
      "0.503208\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.503208\n",
      "Epoch 7/4054\n",
      "0.499088\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.499088\n",
      "Epoch 8/4054\n",
      "0.495783\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.495783\n",
      "Epoch 9/4054\n",
      "0.489587\n",
      "42/42 [==================================================] 100% - 0s 9ms/step - loss: 0.489587\n",
      "Epoch 10/4054\n",
      "0.481303\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.481303\n",
      "Epoch 11/4054\n",
      "0.47021\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.47021\n",
      "Epoch 12/4054\n",
      "0.447273\n",
      "42/42 [==================================================] 100% - 0s 9ms/step - loss: 0.447273\n",
      "Epoch 13/4054\n",
      "0.400468\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.400468\n",
      "Epoch 14/4054\n",
      "0.309344\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.309344\n",
      "Epoch 15/4054\n",
      "0.252523\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.252523\n",
      "Epoch 16/4054\n",
      "0.240686\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.240686\n",
      "Epoch 17/4054\n",
      "0.235446\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.235446\n",
      "Epoch 18/4054\n",
      "0.231156\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.231156\n",
      "Epoch 19/4054\n",
      "0.225518\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.225518\n",
      "Epoch 20/4054\n",
      "0.221857\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.221857\n",
      "Epoch 21/4054\n",
      "0.218079\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.218079\n",
      "Epoch 22/4054\n",
      "0.214044\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.214044\n",
      "Epoch 23/4054\n",
      "0.209868\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.209868\n",
      "Epoch 24/4054\n",
      "0.206621\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.206621\n",
      "Epoch 25/4054\n",
      "0.20263\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.20263\n",
      "Epoch 26/4054\n",
      "0.200574\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.200574\n",
      "Epoch 27/4054\n",
      "0.197565\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.197565\n",
      "Epoch 28/4054\n",
      "0.193354\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.193354\n",
      "Epoch 29/4054\n",
      "0.191899\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.191899\n",
      "Epoch 30/4054\n",
      "0.187392\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.187392\n",
      "Epoch 31/4054\n",
      "0.184551\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.184551\n",
      "Epoch 32/4054\n",
      "0.182099\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.182099\n",
      "Epoch 33/4054\n",
      "0.179014\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.179014\n",
      "Epoch 34/4054\n",
      "0.177297\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.177297\n",
      "Epoch 35/4054\n",
      "0.174459\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.174459\n",
      "Epoch 36/4054\n",
      "0.172149\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.172149\n",
      "Epoch 37/4054\n",
      "0.169619\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.169619\n",
      "Epoch 38/4054\n",
      "0.16699\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.16699\n",
      "Epoch 39/4054\n",
      "0.164336\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.164336\n",
      "Epoch 40/4054\n",
      "0.163377\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.163377\n",
      "Epoch 41/4054\n",
      "0.162547\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.162547\n",
      "Epoch 42/4054\n",
      "0.159095\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.159095\n",
      "Epoch 43/4054\n",
      "0.156879\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.156879\n",
      "Epoch 44/4054\n",
      "0.154546\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.154546\n",
      "Epoch 45/4054\n",
      "0.153572\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.153572\n",
      "Epoch 46/4054\n",
      "0.151117\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.151117\n",
      "Epoch 47/4054\n",
      "0.150036\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.150036\n",
      "Epoch 48/4054\n",
      "0.147585\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.147585\n",
      "Epoch 49/4054\n",
      "0.146416\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.146416\n",
      "Epoch 50/4054\n",
      "0.144204\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.144204\n",
      "Epoch 51/4054\n",
      "0.14174\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.14174\n",
      "Epoch 52/4054\n",
      "0.140988\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.140988\n",
      "Epoch 53/4054\n",
      "0.13909\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.13909\n",
      "Epoch 54/4054\n",
      "0.137\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.137\n",
      "Epoch 55/4054\n",
      "0.135907\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.135907\n",
      "Epoch 56/4054\n",
      "0.133647\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.133647\n",
      "Epoch 57/4054\n",
      "0.132629\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.132629\n",
      "Epoch 58/4054\n",
      "0.13046\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.13046\n",
      "Epoch 59/4054\n",
      "0.127894\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.127894\n",
      "Epoch 60/4054\n",
      "0.128101\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.128101\n",
      "Epoch 61/4054\n",
      "0.125539\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.125539\n",
      "Epoch 62/4054\n",
      "0.12435\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.12435\n",
      "Epoch 63/4054\n",
      "0.122745\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.122745\n",
      "Epoch 64/4054\n",
      "0.121878\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.121878\n",
      "Epoch 65/4054\n",
      "0.119845\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.119845\n",
      "Epoch 66/4054\n",
      "0.118025\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.118025\n",
      "Epoch 67/4054\n",
      "0.116449\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.116449\n",
      "Epoch 68/4054\n",
      "0.114856\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.114856\n",
      "Epoch 69/4054\n",
      "0.115031\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.115031\n",
      "Epoch 70/4054\n",
      "0.11198\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.11198\n",
      "Epoch 71/4054\n",
      "0.111155\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.111155\n",
      "Epoch 72/4054\n",
      "0.10901\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.10901\n",
      "Epoch 73/4054\n",
      "0.106966\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.106966\n",
      "Epoch 74/4054\n",
      "0.106293\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.106293\n",
      "Epoch 75/4054\n",
      "0.103533\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.103533\n",
      "Epoch 76/4054\n",
      "0.102968\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.102968\n",
      "Epoch 77/4054\n",
      "0.101697\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.101697\n",
      "Epoch 78/4054\n",
      "0.10003\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.10003\n",
      "Epoch 79/4054\n",
      "0.0984877\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0984877\n",
      "Epoch 80/4054\n",
      "0.0966137\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0966137\n",
      "Epoch 81/4054\n",
      "0.0953045\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0953045\n",
      "Epoch 82/4054\n",
      "0.095099\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.095099\n",
      "Epoch 83/4054\n",
      "0.0930826\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0930826\n",
      "Epoch 84/4054\n",
      "0.0924395\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0924395\n",
      "Epoch 85/4054\n",
      "0.0894221\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0894221\n",
      "Epoch 86/4054\n",
      "0.0891476\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0891476\n",
      "Epoch 87/4054\n",
      "0.0890234\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0890234\n",
      "Epoch 88/4054\n",
      "0.0874344\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0874344\n",
      "Epoch 89/4054\n",
      "0.0864488\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0864488\n",
      "Epoch 90/4054\n",
      "0.0856573\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0856573\n",
      "Epoch 91/4054\n",
      "0.0853203\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0853203\n",
      "Epoch 92/4054\n",
      "0.0834396\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0834396\n",
      "Epoch 93/4054\n",
      "0.082771\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.082771\n",
      "Epoch 94/4054\n",
      "0.0821954\n",
      "42/42 [==================================================] 100% - 0s 11ms/step - loss: 0.0821954\n",
      "Epoch 95/4054\n",
      "0.0806097\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0806097\n",
      "Epoch 96/4054\n",
      "0.0800969\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0800969\n",
      "Epoch 97/4054\n",
      "0.0796905\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0796905\n",
      "Epoch 98/4054\n",
      "0.0787069\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0787069\n",
      "Epoch 99/4054\n",
      "0.0789468\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0789468\n",
      "Epoch 100/4054\n",
      "0.0772726\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0772726\n",
      "Epoch 101/4054\n",
      "0.0772589\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0772589\n",
      "Epoch 102/4054\n",
      "0.0764594\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0764594\n",
      "Epoch 103/4054\n",
      "0.0755058\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0755058\n",
      "Epoch 104/4054\n",
      "0.0746886\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0746886\n",
      "Epoch 105/4054\n",
      "0.0735825\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0735825\n",
      "Epoch 106/4054\n",
      "0.0742616\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0742616\n",
      "Epoch 107/4054\n",
      "0.0725416\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0725416\n",
      "Epoch 108/4054\n",
      "0.0723\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0723\n",
      "Epoch 109/4054\n",
      "0.0712202\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0712202\n",
      "Epoch 110/4054\n",
      "0.0712616\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0712616\n",
      "Epoch 111/4054\n",
      "0.0704853\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0704853\n",
      "Epoch 112/4054\n",
      "0.0696286\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0696286\n",
      "Epoch 113/4054\n",
      "0.068928\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.068928\n",
      "Epoch 114/4054\n",
      "0.068751\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.068751\n",
      "Epoch 115/4054\n",
      "0.0677736\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0677736\n",
      "Epoch 116/4054\n",
      "0.0677054\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0677054\n",
      "Epoch 117/4054\n",
      "0.0666849\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0666849\n",
      "Epoch 118/4054\n",
      "0.0664908\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0664908\n",
      "Epoch 119/4054\n",
      "0.0662843\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0662843\n",
      "Epoch 120/4054\n",
      "0.0658098\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0658098\n",
      "Epoch 121/4054\n",
      "0.0645775\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0645775\n",
      "Epoch 122/4054\n",
      "0.0640623\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0640623\n",
      "Epoch 123/4054\n",
      "0.0643063\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0643063\n",
      "Epoch 124/4054\n",
      "0.0635026\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0635026\n",
      "Epoch 125/4054\n",
      "0.063051\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.063051\n",
      "Epoch 126/4054\n",
      "0.0631072\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0631072\n",
      "Epoch 127/4054\n",
      "0.0622696\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0622696\n",
      "Epoch 128/4054\n",
      "0.0618589\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0618589\n",
      "Epoch 129/4054\n",
      "0.0614552\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0614552\n",
      "Epoch 130/4054\n",
      "0.0613018\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0613018\n",
      "Epoch 131/4054\n",
      "0.0605534\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0605534\n",
      "Epoch 132/4054\n",
      "0.059976\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.059976\n",
      "Epoch 133/4054\n",
      "0.0603972\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0603972\n",
      "Epoch 134/4054\n",
      "0.0587777\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0587777\n",
      "Epoch 135/4054\n",
      "0.0596507\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0596507\n",
      "Epoch 136/4054\n",
      "0.0585471\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0585471\n",
      "Epoch 137/4054\n",
      "0.0591943\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0591943\n",
      "Epoch 138/4054\n",
      "0.0577108\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0577108\n",
      "Epoch 139/4054\n",
      "0.0569214\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0569214\n",
      "Epoch 140/4054\n",
      "0.0575134\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0575134\n",
      "Epoch 141/4054\n",
      "0.0572123\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0572123\n",
      "Epoch 142/4054\n",
      "0.0566968\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0566968\n",
      "Epoch 143/4054\n",
      "0.0563794\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0563794\n",
      "Epoch 144/4054\n",
      "0.0556649\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0556649\n",
      "Epoch 145/4054\n",
      "0.05581\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.05581\n",
      "Epoch 146/4054\n",
      "0.0555782\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0555782\n",
      "Epoch 147/4054\n",
      "0.0554216\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0554216\n",
      "Epoch 148/4054\n",
      "0.0549881\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0549881\n",
      "Epoch 149/4054\n",
      "0.0542298\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0542298\n",
      "Epoch 150/4054\n",
      "0.0536085\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0536085\n",
      "Epoch 151/4054\n",
      "0.0536241\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0536241\n",
      "Epoch 152/4054\n",
      "0.0534538\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0534538\n",
      "Epoch 153/4054\n",
      "0.0529408\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0529408\n",
      "Epoch 154/4054\n",
      "0.0526187\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0526187\n",
      "Epoch 155/4054\n",
      "0.0526664\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0526664\n",
      "Epoch 156/4054\n",
      "0.0526987\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0526987\n",
      "Epoch 157/4054\n",
      "0.0520703\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0520703\n",
      "Epoch 158/4054\n",
      "0.0511606\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0511606\n",
      "Epoch 159/4054\n",
      "0.0511414\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0511414\n",
      "Epoch 160/4054\n",
      "0.05122\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.05122\n",
      "Epoch 161/4054\n",
      "0.0511272\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0511272\n",
      "Epoch 162/4054\n",
      "0.0498707\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0498707\n",
      "Epoch 163/4054\n",
      "0.0502941\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0502941\n",
      "Epoch 164/4054\n",
      "0.0497101\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0497101\n",
      "Epoch 165/4054\n",
      "0.049693\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.049693\n",
      "Epoch 166/4054\n",
      "0.0497367\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0497367\n",
      "Epoch 167/4054\n",
      "0.0491685\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0491685\n",
      "Epoch 168/4054\n",
      "0.0486356\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0486356\n",
      "Epoch 169/4054\n",
      "0.048544\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.048544\n",
      "Epoch 170/4054\n",
      "0.0482588\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0482588\n",
      "Epoch 171/4054\n",
      "0.0478361\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0478361\n",
      "Epoch 172/4054\n",
      "0.0483954\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0483954\n",
      "Epoch 173/4054\n",
      "0.0470302\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0470302\n",
      "Epoch 174/4054\n",
      "0.0468307\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0468307\n",
      "Epoch 175/4054\n",
      "0.046881\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.046881\n",
      "Epoch 176/4054\n",
      "0.0459022\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0459022\n",
      "Epoch 177/4054\n",
      "0.0455912\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0455912\n",
      "Epoch 178/4054\n",
      "0.0460721\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0460721\n",
      "Epoch 179/4054\n",
      "0.0457361\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0457361\n",
      "Epoch 180/4054\n",
      "0.0454233\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0454233\n",
      "Epoch 181/4054\n",
      "0.0449012\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0449012\n",
      "Epoch 182/4054\n",
      "0.044765\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.044765\n",
      "Epoch 183/4054\n",
      "0.0449801\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0449801\n",
      "Epoch 184/4054\n",
      "0.0437023\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0437023\n",
      "Epoch 185/4054\n",
      "0.0440272\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0440272\n",
      "Epoch 186/4054\n",
      "0.0440999\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0440999\n",
      "Epoch 187/4054\n",
      "0.0440465\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0440465\n",
      "Epoch 188/4054\n",
      "0.0440643\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0440643\n",
      "Epoch 189/4054\n",
      "0.0431433\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0431433\n",
      "Epoch 190/4054\n",
      "0.0433706\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0433706\n",
      "Epoch 191/4054\n",
      "0.0428527\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0428527\n",
      "Epoch 192/4054\n",
      "0.0426871\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0426871\n",
      "Epoch 193/4054\n",
      "0.0426979\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0426979\n",
      "Epoch 194/4054\n",
      "0.042151\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.042151\n",
      "Epoch 195/4054\n",
      "0.0422264\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0422264\n",
      "Epoch 196/4054\n",
      "0.0424282\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0424282\n",
      "Epoch 197/4054\n",
      "0.0422229\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0422229\n",
      "Epoch 198/4054\n",
      "0.0412883\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0412883\n",
      "Epoch 199/4054\n",
      "0.0414889\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0414889\n",
      "Epoch 200/4054\n",
      "0.0413944\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0413944\n",
      "Epoch 201/4054\n",
      "0.0408454\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0408454\n",
      "Epoch 202/4054\n",
      "0.0404015\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0404015\n",
      "Epoch 203/4054\n",
      "0.0407708\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0407708\n",
      "Epoch 204/4054\n",
      "0.0400606\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0400606\n",
      "Epoch 205/4054\n",
      "0.0404709\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0404709\n",
      "Epoch 206/4054\n",
      "0.0398864\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0398864\n",
      "Epoch 207/4054\n",
      "0.0406705\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0406705\n",
      "Epoch 208/4054\n",
      "0.0397967\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0397967\n",
      "Epoch 209/4054\n",
      "0.0396998\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0396998\n",
      "Epoch 210/4054\n",
      "0.0397703\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0397703\n",
      "Epoch 211/4054\n",
      "0.039343\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.039343\n",
      "Epoch 212/4054\n",
      "0.0391344\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0391344\n",
      "Epoch 213/4054\n",
      "0.0391549\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0391549\n",
      "Epoch 214/4054\n",
      "0.0388112\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0388112\n",
      "Epoch 215/4054\n",
      "0.0387353\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0387353\n",
      "Epoch 216/4054\n",
      "0.0381545\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0381545\n",
      "Epoch 217/4054\n",
      "0.0382158\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0382158\n",
      "Epoch 218/4054\n",
      "0.0381416\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0381416\n",
      "Epoch 219/4054\n",
      "0.037841\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.037841\n",
      "Epoch 220/4054\n",
      "0.0382591\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0382591\n",
      "Epoch 221/4054\n",
      "0.0380957\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0380957\n",
      "Epoch 222/4054\n",
      "0.0375933\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0375933\n",
      "Epoch 223/4054\n",
      "0.0374675\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0374675\n",
      "Epoch 224/4054\n",
      "0.0375544\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0375544\n",
      "Epoch 225/4054\n",
      "0.0373351\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0373351\n",
      "Epoch 226/4054\n",
      "0.036653\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.036653\n",
      "Epoch 227/4054\n",
      "0.036632\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.036632\n",
      "Epoch 228/4054\n",
      "0.0364563\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0364563\n",
      "Epoch 229/4054\n",
      "0.0361145\n",
      "42/42 [==================================================] 100% - 0s 11ms/step - loss: 0.0361145\n",
      "Epoch 230/4054\n",
      "0.0350539\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0350539\n",
      "Epoch 231/4054\n",
      "0.0302743\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0302743\n",
      "Epoch 232/4054\n",
      "0.0259984\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0259984\n",
      "Epoch 233/4054\n",
      "0.0245932\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0245932\n",
      "Epoch 234/4054\n",
      "0.023584\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.023584\n",
      "Epoch 235/4054\n",
      "0.0230566\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0230566\n",
      "Epoch 236/4054\n",
      "0.0226058\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0226058\n",
      "Epoch 237/4054\n",
      "0.0218913\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0218913\n",
      "Epoch 238/4054\n",
      "0.0224321\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0224321\n",
      "Epoch 239/4054\n",
      "0.0221995\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0221995\n",
      "Epoch 240/4054\n",
      "0.0214479\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0214479\n",
      "Epoch 241/4054\n",
      "0.0208445\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0208445\n",
      "Epoch 242/4054\n",
      "0.0211928\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0211928\n",
      "Epoch 243/4054\n",
      "0.0207513\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0207513\n",
      "Epoch 244/4054\n",
      "0.0211408\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0211408\n",
      "Epoch 245/4054\n",
      "0.0201614\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0201614\n",
      "Epoch 246/4054\n",
      "0.0204244\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0204244\n",
      "Epoch 247/4054\n",
      "0.0201999\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0201999\n",
      "Epoch 248/4054\n",
      "0.0203673\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0203673\n",
      "Epoch 249/4054\n",
      "0.0196565\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0196565\n",
      "Epoch 250/4054\n",
      "0.0196079\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0196079\n",
      "Epoch 251/4054\n",
      "0.0198333\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0198333\n",
      "Epoch 252/4054\n",
      "0.0193123\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0193123\n",
      "Epoch 253/4054\n",
      "0.0191164\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0191164\n",
      "Epoch 254/4054\n",
      "0.0190592\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0190592\n",
      "Epoch 255/4054\n",
      "0.0190257\n",
      "42/42 [==================================================] 100% - 0s 10ms/step - loss: 0.0190257\n",
      "Epoch 256/4054\n"
     ]
    }
   ],
   "source": [
    "// Train the model.\n",
    "if (bTrain)\n",
    "{\n",
    " std::cout << \"Training ...\" << std::endl;\n",
    "\n",
    " model.Train(trainX,\n",
    "             trainY,\n",
    "             optimizer,\n",
    "             // PrintLoss Callback prints loss for each epoch.\n",
    "             ens::PrintLoss(),\n",
    "             // Progressbar Callback prints progress bar for each epoch. Here 40 signifies width of progress bar.\n",
    "             ens::ProgressBar(40),\n",
    "             // Stops the optimization process if the loss stops decreasing\n",
    "             // or no improvement has been made. This will terminate the\n",
    "             // optimization once we obtain a minima on training set.\n",
    "             ens::EarlyStopAtMinLoss());\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in lstm_multi.bin\n"
     ]
    }
   ],
   "source": [
    "// Save the model.\n",
    "mlpack::data::Save(modelFile, \"LSTMMulti\", model);\n",
    "std::cout << \"Model saved in \" << modelFile << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Load the Trained Model and Run Inference.\n",
    "Load the the model with saved weights and run inference on testing data. This is how the model will be loaded and tested in the real world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ...\n"
     ]
    }
   ],
   "source": [
    "mlpack::ann::RNN<mlpack::ann::MeanSquaredError<>, mlpack::ann::HeInitialization> trainedModel(rho);\n",
    "std::cout << \"Loading model ...\" << std::endl;\n",
    "mlpack::data::Load(modelFile, \"LSTMMulti\", trainedModel);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Run Inference.\n",
    "arma::cube predOutP;\n",
    "trainedModel.Predict(testX, predOutP);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the validation loss.\n",
    "For this purpose we will be calculating Mean Squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "/*\n",
    " * Function to calcute MSE for arma::cube.\n",
    " */\n",
    "double MSE(arma::cube &pred, arma::cube &Y)\n",
    "{\n",
    "  return metric::SquaredEuclideanDistance::Evaluate(pred, Y) / (Y.n_elem);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Prediction data points:= -nan\n"
     ]
    }
   ],
   "source": [
    "// Calculate error on predicted data.\n",
    "long double testMSeEP = MSE(predOutP, testY);\n",
    "std::cout << \"Mean Squared Error on Prediction data points:= \" << testMSeEP << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 6. Save the results.\n",
    "Since the predicted is in form of a cube we need to convert it to matrix with predicted values. Then we take the inverse transform to convert it to meaningful data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * This function saves the input data for prediction and the prediction results\n",
    " * in CSV format. The prediction results are the (high, low) for the next day\n",
    " * and come from the last slice of the prediction. The last 2 columns are the\n",
    " * predictions; the preceding columns are the data used to generate those\n",
    " * predictions.\n",
    " */\n",
    "void SaveResults(const std::string filename,\n",
    "                 const arma::cube& predictions,\n",
    "                 data::MinMaxScaler& scale,\n",
    "                 const arma::cube& testX)\n",
    "{\n",
    "  arma::mat flatDataAndPreds = testX.slice(testX.n_slices - 1);\n",
    "\n",
    "  // The prediction results are the (high, low) for the next day and come from\n",
    "  // the last slice from the prediction.\n",
    "  flatDataAndPreds.rows(flatDataAndPreds.n_rows - 2,\n",
    "                        flatDataAndPreds.n_rows - 1) = predictions.slice(predictions.n_slices - 1);\n",
    "\n",
    "  scale.InverseTransform(flatDataAndPreds, flatDataAndPreds);\n",
    "\n",
    "  // We need to remove the last column because it was not used for training\n",
    "  // (there is no next day to predict).\n",
    "  flatDataAndPreds.shed_col(flatDataAndPreds.n_cols - 1);\n",
    "\n",
    "  // Save the data to file. The last columns are the predictions; the preceding\n",
    "  // columns are the data used to generate those predictions.\n",
    "  mlpack::data::Save(filename, flatDataAndPreds);\n",
    "\n",
    "  // Print the output to screen.\n",
    "  // NOTE: we do not have the last data point in the input for the prediction\n",
    "  // because we did not use it for the training, therefore the prediction result\n",
    "  // will be for the day before. In your own application you may of course load\n",
    "  // any dataset for prediction.\n",
    "  std::cout << \"The predicted Google stock (high, low) for the last day is: \" << std::endl;\n",
    "  std::cout << \"  (\" << flatDataAndPreds(flatDataAndPreds.n_rows - 2, flatDataAndPreds.n_cols - 1) << \", \";\n",
    "  std::cout << flatDataAndPreds(flatDataAndPreds.n_rows - 1, flatDataAndPreds.n_cols - 1) << \")\" << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted Google stock (high, low) for the last day is: \n",
      "  (1051, 1011.52)\n"
     ]
    }
   ],
   "source": [
    "// Save the output predictions and show the results.\n",
    "SaveResults(predFile, predOutP, scale, testX);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++11",
   "language": "C++11",
   "name": "xcpp11"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
